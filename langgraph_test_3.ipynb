{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzuxdA2Kkzp5",
        "outputId": "e59ca7f1-510f-4e7c-a3d8-d2fc7c7e45ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping kfp as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping jupyterlab as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping libpysal as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping ydata-profiling as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Remove conflicting packages from the base environment.\n",
        "!pip uninstall -qqy kfp jupyterlab libpysal thinc spacy fastai ydata-profiling google-cloud-bigquery google-generativeai\n",
        "\n",
        "# Install langgraph and the packages needed.\n",
        "!pip install -qU 'langgraph==0.3.21' 'langchain-google-genai==2.1.2' 'langgraph-prebuilt==0.1.7'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "from pprint import pprint\n",
        "from random import randint\n",
        "from typing import List, Dict, Any, Annotated, Literal, Optional\n",
        "from collections.abc import Iterable\n",
        "from typing_extensions import TypedDict\n",
        "from IPython.display import Image, display\n",
        "\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_core.messages.tool import ToolMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "mz6xIO6ok2ob"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup API key for Gemini\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"not-that-dumb\""
      ],
      "metadata": {
        "id": "KwwS12HVk4ua"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PCBuilderState(TypedDict):\n",
        "    \"\"\"State representing the PC builder conversation.\"\"\"\n",
        "\n",
        "    # The chat conversation. This preserves the conversation history\n",
        "    # between nodes. The `add_messages` annotation indicates to LangGraph\n",
        "    # that state is updated by appending returned messages, not replacing\n",
        "    # them.\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "    # User requirements\n",
        "    # requirements: Dict[str, Any]\n",
        "    requirements: list[str]\n",
        "\n",
        "    # Budget information\n",
        "    budget: str\n",
        "\n",
        "    # Current recommendations for parts\n",
        "    recommendations: list[Dict[str, Any]]\n",
        "\n",
        "    # Flag for whether the build is complete\n",
        "    build_complete: bool\n",
        "\n",
        "    # Flag to indicate waiting for user input\n",
        "    # waiting_for_user: bool\n",
        "\n",
        "\n",
        "# The system instruction defines how the chatbot is expected to behave and includes\n",
        "# rules for when to call different functions, as well as rules for the conversation, such\n",
        "# as tone and what is permitted for discussion.\n",
        "PC_BUILDER_SYSINT = (\n",
        "    \"system\",  # 'system' indicates the message is a system instruction.\n",
        "    \"\"\"\n",
        "You are a PC Builder Assistant, an expert in computer hardware and building custom PCs.\n",
        "Your goal is to help users find the perfect PC build based on their budget and requirements.\n",
        "\n",
        "You should:\n",
        "1. Ask about their budget and use case (gaming, office work, content creation, etc.)\n",
        "2. Determine if they need a custom build or pre-built system.\n",
        "3. For pre-built systems, ask if desktops or laptops or either are preferred.\n",
        "4. For custom builds, if they have existing hardware, ask what parts they want to upgrade.\n",
        "\n",
        "Once you have a general idea of what the user is looking for, you must formulate that\n",
        "into a structured list of concise individual requirements and call the update_plans tool,\n",
        "providing the budget and list of requirements. For custom build devices, if the user\n",
        "mentions wanting the PC for a specific task that is hardware intensive, such as playing a\n",
        "video game or video editing or training AI models or such, then first use the\n",
        "search_task_requirements tool to find the hardware requirements for the specified task,\n",
        "and only then update the user requirements using the update_plans tool, with the extra\n",
        "hardware requirements added to it.\n",
        "\n",
        "For pre-builds, even if there are potentially-intensive task requirements, you can call\n",
        "the update_plans tool directly, adding the task requirements as part of the main requirements.\n",
        "\n",
        "Once the requirements are all logged by the tool, summarize the requirements back to the\n",
        "user in a couple of sentences using the latest requirements list and budget returned by\n",
        "your last call of the tool.\n",
        "\n",
        "If the user wants to change something in their plans, send a new list of requirements back\n",
        "to update_plans. If they want to start from scratch, use the clear_plan tool to remove all\n",
        "budget and requirements, then walk through the requirements gathering steps again.\n",
        "\n",
        "If the user confirms their requirements are final and they want a pre-built device, use\n",
        "search_prebuilt tool to find pre-built devices fitting the user criteria, which will be\n",
        "given to you in a structured JSON format. If the JSON has formatting errors and you cannot\n",
        "understand it, recall the search_prebuilt tool. If the JSON can be understood, call the\n",
        "rank_prebuilds tool to get a final list of recommendations and then render this neatly in\n",
        "markdown for the user to browse.\n",
        "\n",
        "If the user confirms their requirements are final and they want a custom build, use the\n",
        "lookup_parts_needed tool to get a list of the parts required. Once you have the parts,\n",
        "call the search_custom_parts tool to get a list of parts, which should be in a structured\n",
        "JSON format. If the JSON has formatting errors and you cannot understand it, recall the\n",
        "search_custom_parts tool. If the JSON can be understood, call the rank_parts tool to get\n",
        "a final list of parts for the user. Render this neatly in markdown for the user to browse.\n",
        "\n",
        "The user may have additional questions about the parts or building process, which you must\n",
        "expand upon if asked.\n",
        "\n",
        "If any of the tools are unavailable, let the user know instead of trying to call the tools.\n",
        "\n",
        "Stay focused on PC building. If users ask about unrelated topics, gently redirect them.\n",
        "\"\"\",\n",
        ")\n",
        "\n",
        "# This is the message with which the system opens the conversation.\n",
        "WELCOME_MSG = \"Welcome to the PC Builder Assistant! (Type `q` to quit). I'll help you find the perfect computer based on your needs and budget. Could you tell me your budget and what you'll be using this PC for? (Gaming, office work, content creation, etc.)\""
      ],
      "metadata": {
        "id": "86ysZFyXk6W6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM model definition\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")"
      ],
      "metadata": {
        "id": "4KH2vWTY3sZR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stateless tool - Search online for pre-built devices\n",
        "\n",
        "@tool\n",
        "def search_prebuilt(budget: str, requirements: list[str]) -> str:\n",
        "    '''Search for pre-built desktops or laptops fulfilling the user criteria.\n",
        "    Take the budget and requirements, and get Gemini to format it into a terse, concise query.\n",
        "    Then use search grounding to look for it and return the output as structured JSON with\n",
        "    price, brand, desktop/laptop, name, link to view more or buy\n",
        "    '''\n",
        "\n",
        "    USE_LANGGRAPH_SEARCH = False  # Will use Gemini search if false, both techniques seem to hallucinate info\n",
        "\n",
        "    USE_MODEL = 'gemini-2.0-flash'\n",
        "\n",
        "    newline_char = '\\n'\n",
        "\n",
        "    search_config = types.GenerateContentConfig(\n",
        "        tools=[types.Tool(google_search=types.GoogleSearch())],\n",
        "        temperature=0.0\n",
        "    )\n",
        "\n",
        "    prompt = f'''\n",
        "You are a computer hardware specialist who always responds in valid JSON. Search online\n",
        "for pre-built laptops or desktops based on the requirements provided below and return\n",
        "the results in JSON format with name, price, specifications, and purchase link for each\n",
        "device. Find at least 3-6 options for the device in question.\n",
        "\n",
        "JSON Structure to follow:\n",
        "Return a list of objects, where each object has three fields: name, price, and specifications.\n",
        "\n",
        "Key points to note:\n",
        "- Please answer the following question using ONLY information found in the provided web search results. Cite your sources for each statement or paragraph.\n",
        "- Rely exclusively on the real-time search results to answer. For each device in the JSON list you make, indicate which search result supports it.\n",
        "\n",
        "Device Requirements:\n",
        "    1. Budget: {'$600'}\n",
        "    2. Requirements: {newline_char + (newline_char.join([((' ' * 8) + '- ' + req) for req in requirements]))}\n",
        "'''\n",
        "\n",
        "    response = None\n",
        "\n",
        "    if USE_LANGGRAPH_SEARCH:\n",
        "        search_model = ChatGoogleGenerativeAI(\n",
        "            model=USE_MODEL,\n",
        "            config=search_config,\n",
        "            # convert_system_message_to_human=True  # Handle system messages properly\n",
        "        )\n",
        "        response = search_model.invoke([\n",
        "            HumanMessage(content=prompt)\n",
        "        ])\n",
        "        return response.content\n",
        "    else:\n",
        "        client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "        response = client.models.generate_content(\n",
        "            model=USE_MODEL,\n",
        "            contents=prompt,\n",
        "            config=search_config\n",
        "        )\n",
        "        rc = response.candidates[0]\n",
        "        return rc.content.parts[0].text"
      ],
      "metadata": {
        "id": "DxR35j6D_kBh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stateless tool - Search hardware requirements for a particular task\n",
        "@tool\n",
        "def search_task_requirements():\n",
        "    '''\n",
        "    '''"
      ],
      "metadata": {
        "id": "_CrjI_sD-Cp1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stateless tool - Lookup parts required internally using RAG and rules of thumb\n",
        "@tool\n",
        "def lookup_parts_needed():\n",
        "    '''\n",
        "    '''\n",
        "'''\n",
        "4. For custom builds, recommend parts following these rules:\n",
        "   - GPU: ~50% of total budget\n",
        "   - CPU: Should not bottleneck the GPU\n",
        "   - Motherboard: Quality based on other components\n",
        "   - RAM: Compatible with CPU/motherboard overclocking specs\n",
        "   - PSU: At least 10% headroom over expected power draw, 20-30% for future upgrades\n",
        "   - Storage: Prioritize SSDs for budget builds, M.2 for pro builds, HDDs only if necessary\n",
        "   - Cooler: Appropriate for the CPU (no air cooling for hot CPUs)\n",
        "   - Case: Compatible with GPU length, motherboard type, and storage needs\n",
        "   - Fans: Minimum 3 fans (2 intake, 1 exhaust)\n",
        "'''"
      ],
      "metadata": {
        "id": "EwN9E2H-STbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "719f72a4-0603-462c-aad3-b7f9d121d2f5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n4. For custom builds, recommend parts following these rules:\\n   - GPU: ~50% of total budget\\n   - CPU: Should not bottleneck the GPU\\n   - Motherboard: Quality based on other components\\n   - RAM: Compatible with CPU/motherboard overclocking specs\\n   - PSU: At least 10% headroom over expected power draw, 20-30% for future upgrades\\n   - Storage: Prioritize SSDs for budget builds, M.2 for pro builds, HDDs only if necessary\\n   - Cooler: Appropriate for the CPU (no air cooling for hot CPUs)\\n   - Case: Compatible with GPU length, motherboard type, and storage needs\\n   - Fans: Minimum 3 fans (2 intake, 1 exhaust)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All stateless tools, part of tools node: Search game specs, lookup parts needed (sends to\n",
        "# chatbot which then sends to search part then back to chatbot which then updates\n",
        "# recommendations; must also take in existing hardware), search custom part (searches\n",
        "# each part mentioned by lookup parts, takes in list of strs from chatbot or directly\n",
        "# from lookup, does google search or external api call,  returns json for each part) ->\n",
        "# this then goes to optimize build and then gets put in recommendations."
      ],
      "metadata": {
        "id": "uBW2Y_RdSwTh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stateless tool - Search online for custom parts for the build\n",
        "@tool\n",
        "def search_custom_parts():\n",
        "    '''\n",
        "    '''"
      ],
      "metadata": {
        "id": "_Hjm6RUkVbsJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tool signatures for planning the build\n",
        "# Functionality defined in pc_planner_node\n",
        "@tool\n",
        "def update_plans(requirements: Iterable[str], budget: Optional[str] = None) -> Dict[str, Any]:\n",
        "    '''\n",
        "    Adds or modifies the device requirements and budget.\n",
        "    Returns a confirmation of the budget and requirements that were just added to state.\n",
        "    '''\n",
        "\n",
        "\n",
        "@tool\n",
        "def clear_plan():\n",
        "    '''\n",
        "    Removes all requirements and budget information and resets to blank slate.\n",
        "    '''"
      ],
      "metadata": {
        "id": "SdoWxZlJIoUb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tool signatures for recommending parts for a planned build\n",
        "# Functionality defined in optimize_build_node\n",
        "@tool\n",
        "def rank_parts():\n",
        "    '''\n",
        "    Takes in a list of parts in JSON and a budget and returns the most\n",
        "    performant yet price-optimal parts for each part.\n",
        "    Modifies state by adding the parts to the recommendations list.\n",
        "    '''\n",
        "\n",
        "\n",
        "@tool\n",
        "def rank_prebuilds(recommended_devices: str = '') -> str:\n",
        "    '''\n",
        "    Takes in a list of prebuilt devices in JSON and a budget and returns the top\n",
        "    three most performant yet price-optimal devices, also in JSON.\n",
        "    Modifies state by adding the devices to the recommendations list.\n",
        "    '''"
      ],
      "metadata": {
        "id": "3BVtk0cTIroB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions required to rank pre-built devices\n",
        "\n",
        "def parse_price(price_str: str) -> float:\n",
        "    '''Extract numeric price value from the provided string.'''\n",
        "    # Extract digits and decimal value\n",
        "    price_match = re.search(r'[\\d,.]+', price_str)\n",
        "    if not price_match:\n",
        "        return 0.0\n",
        "\n",
        "    # Remove commas and convert to float\n",
        "    price_digits = price_match.group(0).replace(',', '')\n",
        "    return float(price_digits)\n",
        "\n",
        "\n",
        "def score_specs(specs: str) -> int:\n",
        "    \"\"\"\n",
        "    Analyze specifications to score device performance.\n",
        "    Higher scores indicate better performance.\n",
        "    \"\"\"\n",
        "    score = 0\n",
        "    specs = specs.lower()\n",
        "\n",
        "    # CPU scoring\n",
        "    if 'ryzen 7' in specs or 'i7' in specs:\n",
        "        score += 80\n",
        "    elif 'ryzen 5' in specs or 'i5' in specs:\n",
        "        score += 60\n",
        "    elif 'ryzen 3' in specs or 'i3' in specs:\n",
        "        score += 40\n",
        "\n",
        "    # Generation bonus\n",
        "    if '5700' in specs:\n",
        "        score += 20\n",
        "    elif '5600' in specs or '5500' in specs:\n",
        "        score += 15\n",
        "    elif '4500' in specs or '4600' in specs:\n",
        "        score += 10\n",
        "\n",
        "    # RAM scoring\n",
        "    ram_match = re.search(r'(\\d+)gb', specs.replace(' ', ''))\n",
        "    if ram_match:\n",
        "        ram_size = int(ram_match.group(1))\n",
        "        if ram_size >= 32:\n",
        "            score += 50\n",
        "        elif ram_size >= 16:\n",
        "            score += 30\n",
        "        elif ram_size >= 8:\n",
        "            score += 15\n",
        "\n",
        "    # Storage scoring\n",
        "    if '1tb' in specs.replace(' ', ''):\n",
        "        score += 30\n",
        "    elif '500gb' in specs.replace(' ', '') or '512gb' in specs.replace(' ', ''):\n",
        "        score += 20\n",
        "\n",
        "    if 'nvme' in specs or 'ssd' in specs:\n",
        "        score += 20\n",
        "\n",
        "    # GPU scoring\n",
        "    if 'rtx 3080' in specs:\n",
        "        score += 100\n",
        "    elif 'rtx 3070' in specs:\n",
        "        score += 80\n",
        "    elif 'rtx 3060' in specs:\n",
        "        score += 70\n",
        "    elif 'gtx 1650' in specs:\n",
        "        score += 40\n",
        "    elif 'radeon' in specs or 'onboard' in specs:\n",
        "        score += 20\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "def get_value_ratio(device: Dict[str, Any], budget: float) -> float:\n",
        "    \"\"\"\n",
        "    Calculate value ratio based on specs score and price.\n",
        "    Returns 0 if device exceeds budget.\n",
        "    \"\"\"\n",
        "    price = parse_price(device['price'])\n",
        "    if price > budget:\n",
        "        return 0\n",
        "\n",
        "    specs_score = score_specs(device['specifications'])\n",
        "\n",
        "    # Calculate value ratio (specs score per unit of price)\n",
        "    # Higher ratio means better value\n",
        "    if price > 0:\n",
        "        return specs_score / price\n",
        "    return 0\n",
        "\n",
        "\n",
        "def rank_devices(devices_json: str, budget: float, return_json: Optional[bool] = False) -> Any:\n",
        "    '''\n",
        "    Rank devices based on specifications and price within budget.\n",
        "    Returns JSON string with top 3 devices.\n",
        "    '''\n",
        "    devices = json.loads(devices_json)\n",
        "\n",
        "    for device in devices:\n",
        "        device['value_ratio'] = get_value_ratio(device, budget)\n",
        "\n",
        "    # Sort devices by assigned value ratios descending\n",
        "    ranked_devices = sorted(devices, key=lambda x: x['value_ratio'], reverse=True)\n",
        "\n",
        "    # Select top 3 within budget\n",
        "    top_devices = [\n",
        "        {k: v for k, v in device.items() if k != 'value_ratio'}\n",
        "        for device in ranked_devices[:3] if parse_price(device['price']) <= budget\n",
        "    ]\n",
        "\n",
        "    if return_json:\n",
        "        return json.dumps(top_devices, indent=4, ensure_ascii=False)\n",
        "    return top_devices"
      ],
      "metadata": {
        "id": "tCsnnXgSCcw6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tool grouped on nodes\n",
        "planner_tools = [update_plans, clear_plan]\n",
        "builder_tools = [rank_parts, rank_prebuilds]"
      ],
      "metadata": {
        "id": "M-9DAAU6QH6i"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tools Config\n",
        "auto_tools = [search_prebuilt, search_task_requirements, lookup_parts_needed, search_custom_parts]\n",
        "tool_node = ToolNode(auto_tools)\n",
        "\n",
        "# Tool binding\n",
        "llm_with_tools = llm.bind_tools(auto_tools + planner_tools + builder_tools)"
      ],
      "metadata": {
        "id": "pXXPDrGKA8_6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build planner node\n",
        "def pc_planner_node(state: PCBuilderState) -> PCBuilderState:\n",
        "    '''This is where the requirements and budget within state get manipulated.'''\n",
        "\n",
        "    tool_msg = state.get(\"messages\", [])[-1]\n",
        "    requirements_state = state.get(\"requirements\", [])\n",
        "    budget_state = state.get('budget', None)\n",
        "    recommendations_state = state.get('recommendations', [])\n",
        "    outbound_msgs = []\n",
        "    build_complete = state.get('build_complete', False)\n",
        "\n",
        "    for tool_call in tool_msg.tool_calls:\n",
        "        if tool_call['name'] == 'update_plans':\n",
        "            requirements_arg = tool_call['args']['requirements']\n",
        "            budget_arg = tool_call['args']['budget']\n",
        "            # If budget is None and nothing exists in state, raise an error.\n",
        "            # If there is something in state, then just don't update it.\n",
        "            # Otherwise always update the budget.\n",
        "            if budget_arg is None or len(budget_arg) < 1:\n",
        "                if budget_state is None or len(budget_state) < 1:\n",
        "                    raise ValueError(f'Budget is missing in tool call as well as state!')\n",
        "            else:\n",
        "                budget_state = budget_arg\n",
        "            if requirements_arg is None or len(requirements_arg) < 1:\n",
        "                raise ValueError('Requirements are missing in tool call!')\n",
        "            else:\n",
        "                requirements_state = [requirement for requirement in requirements_arg]\n",
        "            response = {\n",
        "                'budget': budget_arg if budget_arg is not None else budget_state,\n",
        "                'requirements': requirements_arg\n",
        "            }\n",
        "\n",
        "        elif tool_call['name'] == 'clear_plan':\n",
        "            requirements_state = []\n",
        "            budget_state = None\n",
        "            response = None\n",
        "\n",
        "        else:\n",
        "            raise NotImplementedError(f'Unknown tool call: {tool_call[\"name\"]}')\n",
        "\n",
        "        # Record the tool results as tool messages.\n",
        "        outbound_msgs.append(\n",
        "            ToolMessage(\n",
        "                content=response,\n",
        "                name=tool_call[\"name\"],\n",
        "                tool_call_id=tool_call[\"id\"],\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return {\n",
        "        \"messages\": outbound_msgs,\n",
        "        \"requirements\": requirements_state,\n",
        "        'budget': budget_state,\n",
        "        'recommendations': recommendations_state,\n",
        "        \"build_complete\": build_complete\n",
        "    }"
      ],
      "metadata": {
        "id": "9BmdR5L5I0-i"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parts recommender node (based on devised plan and recommended devices)\n",
        "def optimize_build_node(state: PCBuilderState) -> PCBuilderState:\n",
        "    '''This is where the recommendations within state get manipulated.'''\n",
        "    # state.recommendations modified by tool rank_parts() part of optimize_build node\n",
        "    # - happens once search_prebuilt() tool returns a few values\n",
        "\n",
        "    tool_msg = state.get(\"messages\", [])[-1]\n",
        "    requirements_state = state.get(\"requirements\", [])\n",
        "    budget_state = state.get('budget', None)\n",
        "    recommendations_state = state.get('recommendations', [])\n",
        "    outbound_msgs = []\n",
        "    build_complete = state.get('build_complete', False)\n",
        "\n",
        "    for tool_call in tool_msg.tool_calls:\n",
        "        if tool_call['name'] == 'rank_parts':\n",
        "            pass\n",
        "\n",
        "        elif tool_call['name'] == 'rank_prebuilds':\n",
        "            recommended_devices = tool_call['args']['recommended_devices']\n",
        "            if budget_state is None or len(budget_state) < 1:\n",
        "                raise ValueError(f'An invalid budget of NoneType was found!')\n",
        "            recommendations_state = rank_devices(recommended_devices, parse_price(budget_state))\n",
        "            response = rank_devices(recommended_devices, parse_price(budget_state), True)\n",
        "\n",
        "        else:\n",
        "            raise NotImplementedError(f'Unknown tool call: {tool_call[\"name\"]}')\n",
        "\n",
        "        # Record the tool results as tool messages.\n",
        "        outbound_msgs.append(\n",
        "            ToolMessage(\n",
        "                content=response,\n",
        "                name=tool_call[\"name\"],\n",
        "                tool_call_id=tool_call[\"id\"],\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return {\n",
        "        \"messages\": outbound_msgs,\n",
        "        \"requirements\": requirements_state,\n",
        "        'budget': budget_state,\n",
        "        'recommendations': recommendations_state,\n",
        "        \"build_complete\": build_complete\n",
        "    }"
      ],
      "metadata": {
        "id": "51rRWwKoI2yq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_node(state: PCBuilderState) -> PCBuilderState:\n",
        "    \"\"\"The chatbot itself. A simple wrapper around the model's own chat interface.\"\"\"\n",
        "    default_state = {'requirements': [], 'budget': None, 'build_complete': False}\n",
        "\n",
        "    if state['messages']:\n",
        "        # If there are messages, continue the conversation with the model\n",
        "        message_history = [PC_BUILDER_SYSINT] + state[\"messages\"]\n",
        "        new_output = llm_with_tools.invoke(message_history)\n",
        "    else:\n",
        "        # If there are no messages, welcome the user.\n",
        "        new_output = AIMessage(content=WELCOME_MSG)\n",
        "\n",
        "    # Setup some defaults, then override with whatever exists in state, and finally\n",
        "    # override with messages\n",
        "    return default_state | state | {\"messages\": [new_output]}"
      ],
      "metadata": {
        "id": "lzsqL221mQUL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def human_node(state: PCBuilderState) -> PCBuilderState:\n",
        "    \"\"\"Display the last message from the model to the user, and receive their input.\"\"\"\n",
        "    last_msg = state['messages'][-1]\n",
        "    print('Model:', last_msg.content)\n",
        "\n",
        "    user_input = input('User: ')\n",
        "\n",
        "    # Does the user wish to quit?\n",
        "    if user_input in {'q', 'quit', 'exit', 'goodbye'}:\n",
        "        state['build_complete'] = True\n",
        "\n",
        "    return state | {'messages': [('user', user_input)]}"
      ],
      "metadata": {
        "id": "ooizLUht1wRS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Human to Exit OR Human to Chatbot; Conditional Edge Transition function\n",
        "def maybe_exit_human_node(state: PCBuilderState) -> Literal[\"chatbot\", \"__end__\"]:\n",
        "    \"\"\"Route to the chatbot, unless it looks like the user is exiting.\"\"\"\n",
        "    if state.get(\"build_complete\", False):\n",
        "        return END\n",
        "    else:\n",
        "        return \"chatbot\""
      ],
      "metadata": {
        "id": "gqmUpWsu4wPZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chatbot to Tools OR Chatbot to Human; Conditional Edge Transition function\n",
        "def maybe_route_to_tools(state: PCBuilderState) -> Literal['tools', 'human']:\n",
        "    if not (msgs := state.get('messages', [])):\n",
        "        raise ValueError(f'No messages found when parsing state: {state}')\n",
        "\n",
        "    # Only route based on the last message.\n",
        "    msg = msgs[-1]\n",
        "\n",
        "    if state.get('build_complete', False):\n",
        "        # If the user has no more questions or indicate satisfaction, complete the build\n",
        "        return END\n",
        "    elif hasattr(msg, 'tool_calls') and len(msg.tool_calls) > 0:\n",
        "        # When chatbot returns tool_calls, route to the 'tools' node\n",
        "        if any(tool['name'] in tool_node.tools_by_name.keys() for tool in msg.tool_calls):\n",
        "            return 'tools'\n",
        "        else:\n",
        "            if any(tool['name'] in planner_tools.tools_by_name.keys() for tool in msg.tool_calls):\n",
        "                return 'pc_planner'\n",
        "            # elif tool['name'] in [func.__name__ for func in planner_tools]:\n",
        "            #     return 'pc_planner'\n",
        "            elif tool['name'] in [func.__name__ for func in builder_tools]:\n",
        "                return 'optimize_build'\n",
        "            else:\n",
        "                raise ValueError(f'No such node existent: {tool[\"name\"]}')\n",
        "    else:\n",
        "        return 'human'"
      ],
      "metadata": {
        "id": "gH9EZoIkBXWH"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the initial graph based on our state definition.\n",
        "graph_builder = StateGraph(PCBuilderState)\n",
        "\n",
        "# Add all the nodes to the app graph.\n",
        "graph_builder.add_node(\"chatbot\", chatbot_node)\n",
        "graph_builder.add_node(\"human\", human_node)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "graph_builder.add_node(\"pc_planner\", tool_node)\n",
        "graph_builder.add_node(\"optimize_build\", tool_node)\n",
        "\n",
        "# Define the chatbot node as the app entrypoint.\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "\n",
        "# Edge transitions\n",
        "graph_builder.add_conditional_edges(\"chatbot\", maybe_route_to_tools)\n",
        "graph_builder.add_conditional_edges(\"human\", maybe_exit_human_node)\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(\"pc_planner\", \"chatbot\")\n",
        "graph_builder.add_edge(\"optimize_build\", \"chatbot\")\n",
        "\n",
        "chat_graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "vz-kOlcOwKry"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the graph created.\n",
        "Image(chat_graph.get_graph().draw_mermaid_png())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "quysN6udx6zb",
        "outputId": "dea01f57-1b04-4c34-87e2-140e78d111e3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The default recursion limit for traversing nodes is 25 - setting it higher means\n",
        "# you can try a more complex order with multiple steps and round-trips (and you\n",
        "# can chat for longer!)\n",
        "config = {\"recursion_limit\": 100}\n",
        "\n",
        "# Remember that this will loop forever, unless you input `q`, `quit` or one of the\n",
        "# other exit terms defined in `human_node`.\n",
        "# Uncomment this line to execute the graph:\n",
        "state = chat_graph.invoke({\"messages\": []}, config)\n",
        "\n",
        "# Things to try:\n",
        "#  - Just chat! There's no ordering or menu yet.\n",
        "#  - 'q' to exit.\n",
        "\n",
        "pprint(state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VDcqNgjV0KES",
        "outputId": "0d5c2912-d077-4b5d-f029-13793120ec38"
      },
      "execution_count": 35,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Welcome to the PC Builder Assistant! (Type `q` to quit). I'll help you find the perfect computer based on your needs and budget. Could you tell me your budget and what you'll be using this PC for? (Gaming, office work, content creation, etc.)\n",
            "User: Office work\n",
            "Model: Got it. And do you have any preference for a pre-built system or would you like to explore a custom build? Also, for pre-built systems, do you prefer a desktop or a laptop, or are either okay?\n",
            "User: I'm fine with either type of PC, I just dont want to build anything myself\n",
            "Model: Understood. So you're looking for a pre-built system (either desktop or laptop) for office work. What is your budget?\n",
            "User: Around $500\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'function' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-4d80497eabb5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# other exit terms defined in `human_node`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Uncomment this line to execute the graph:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Things to try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2681\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2682\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2683\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   2684\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2685\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2329\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2331\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2332\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2333\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    147\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    606\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/graph/branch.py\u001b[0m in \u001b[0;36m_route\u001b[0;34m(self, input, config, reader, writer)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mchild_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_config\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m                     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-4b45818f95df>\u001b[0m in \u001b[0;36mmaybe_route_to_tools\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtool_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools_by_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtool\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m'tools'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplanner_tools\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m'pc_planner'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbuilder_tools\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'function' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_msg = \"Oh great, I plan to use the PC for university work, I'm enrolled in a computer science course.\"\n",
        "\n",
        "state[\"messages\"].append(user_msg)\n",
        "state = chat_graph.invoke(state)\n",
        "\n",
        "# pprint(state)\n",
        "for msg in state[\"messages\"]:\n",
        "    print(f\"{type(msg).__name__}: {msg.content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBfxl2JT0_va",
        "outputId": "f9ea7a6d-a72c-4a05-dd05-7fc5913b74a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HumanMessage: Hello, what can you do?\n",
            "AIMessage: Hello! I'm your PC Building Assistant. I can help you find the perfect PC build based on your budget and needs.\n",
            "\n",
            "To get started, could you tell me:\n",
            "\n",
            "1.  What is your budget for the PC?\n",
            "2.  What will you primarily use the PC for (e.g., gaming, office work, content creation, etc.)?\n",
            "HumanMessage: Oh great, I plan to use the PC for university work, I'm enrolled in a computer science course.\n",
            "AIMessage: Okay, a PC for computer science coursework. That's a good starting point. To give you the best recommendations, I need a little more information:\n",
            "\n",
            "1.  What's your budget? Even a rough estimate is helpful.\n",
            "2.  Do you need a pre-built system, or are you interested in building your own?\n",
            "3.  Do you have any existing hardware (monitor, keyboard, mouse, etc.) that you plan to use?\n",
            "4.  Are there any specific programs or tasks you anticipate using frequently (e.g., virtual machines, specific IDEs, data analysis)?\n",
            "\n",
            "Once I have this information, I can start putting together some potential build options for you.\n"
          ]
        }
      ]
    }
  ]
}